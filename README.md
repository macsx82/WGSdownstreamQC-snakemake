# Post variant calling QC of WGS pipeline

The pipeline will perform some QC steps on a complete WGS dataset, on both variants and samples.

Variant related QC and metrics:

- [x] VQSR reapply
- [x] HWE
- [x] Heterozygosity rate
- [x] Call rate
- [x] Allele Frequency comparison with outbred populations

For a subset of individuals (all the INGI-FVG samples) also the following information were extracted:

- [x] Allele Frequency comparison with available snp array data
- [x] Non Reference Discordance (NRD) comparison with available snp array data


Sample related:

- [x] Singleton distribution
- [x] Missingness
- [x] Coverage
- [x] Heterozygosity rate
- [x] PCA
- [x] PCA with 1000G

The pipeline will generate lists of samples or sites flagged for removal to generate the final dataset.
Only sites exceeding the user specified thresholds for HWE pvalue and missing rate will be removed automatically.


The pipeline will generate the following plots, to help data interpretation:

- [x] Singletons vs NRD
- [x] Allele Frequency comparison with outbred pop (all variants)
- [x] Allele Frequency comparison with outbred pop (most diverse variants)
- [x] Allele Frequency comparison with SNP array data (all variants)
- [x] Allele Frequency comparison with SNP array data (most diverse variants)
- [x] Read Depth (DP) vs Singletons
- [x] Het Rate distribution by sample
- [x] PCA
- [x] PCA with 1000G



The final data release has to be generated by hand, excluding samples and sites following the evaluation of the generated summaries (tables and plots).

---

## Setting things up

In order to run the pipeline, there are some requirements to fullfill and some set up needs to be perfomed.
In this current version, the pipeline is tested and configured to be run on the [ORFEO cluster](https://orfeo-documentation.readthedocs.io/en/latest/) .
It is possible to run the pipeline on the Apollo cluster, but it will require to manually specify the location of all software binaries in the provided config file.

### Required Software

The following software has to be installed system-wide, in a user-defined Conda environment or using the modules architecture (ORFEO cluster).

+ awk
+ sed
+ python3
+ [bcftools](http://www.htslib.org/doc/)
+ [vcftools](https://vcftools.github.io/man_latest.html)
+ [plink](https://www.cog-genomics.org/plink/1.9/)
+ [king](https://www.kingrelatedness.com/)
+ R
+ git
+ snakemake

At the moment, the load directive of each module on the ORFEO cluster is hard-coded in the pipeline code, with the form "module-name/version". Modules and versions used are:

+ bcftools/1.14
+ vcftools/0.1.16
+ plink/1.90
+ R/4.0.3

**Before switching to a new version of each software/module, a test run should be performed to check that the expected output files are generated and that they are consistent with the previous production version.**

### Required python packages

In order to run the pipeline, the following python packages have to be installed in your conda environment or system wide:

+ errno
+ gzip 
+ io
+ multiprocessing
+ os
+ pandas
+ pathlib
+ psutil
+ re
+ sys
+ matplotlib
+ numpy
+ collections


### ORFEO/general set up
1. Install Snakemake via conda ([link](https://snakemake.readthedocs.io/en/stable/getting\_started/installation.html));
    ```bash
    conda create -c conda-forge -c bioconda -n snakemake snakemake pandas
    ```
2. Activate the environment you created
    ```bash
    conda activate snakemake
    ```

### Apollo set up

1. Add the global snakemake environment to your environment list:
    ```bash
    conda config --append envs_dirs /shared/software/conda/envs
    conda config --prepend envs_dirs ~/.conda/envs
    ```

2. Check that the environment is available to you (you should see an entry "snakemake_g" in the list)
    ```bash
    conda env list
    ```
3. Load the environment
    ```bash
    conda activate snakemake_g
    ```
---

## Resources set up

In order to run the pipeline, some resources have to be available on you cluster/environment.

### Genome reference

At the moment, all resources needed are already available on the APOLLO cluster, at the following locations:

```
################### REFERENCES  #####################################
#paths and subfolders containing data we need for the pipeline to run
references:
  basepath: "/shared/resources"
  provider: "hgRef"
  release: "GRCh38.p13"

genome_fasta: "GCA_000001405.15_GRCh38_full_plus_hs38d1_analysis_set.fna"
```

### Outbred population references

In order to perform allele frequency comparison with external populations, two resources are required, and their path has to be specified in the comparePopAF block of the config file:

```
1000G_subpop: "/storage/burlo/cocca/resources/1000GP_phase3_3202/vcf/EUR/EUR_normIndel_multiSplitted.vcf.gz.tab" #full path of the file containing AF information for fomparison with the study population. This file should be defined according to the main ancestry represented in your population
TGP2504: "/storage/burlo/cocca/resources/1000GP_phase3_3202/vcf/TGP_2504/TGP2504_normIndel_multiSplitted.vcf.gz.tab" #full path of the file containing AF information for fomparison with the study population
```

The examples provided here refers to resources available on the ORFEO cluster. The main path for resources on the Apoloo cluster is:

```
/shared/resources
```

### PCA resources

PCA analyses is performed using the [King software](https://www.kingrelatedness.com/) . In roder to perform the analyses, the user need to define the correct resource path using the parameter **1000G_ref_for_king** in the config file.

The default value below is set to work on the ORFEO cluster

```
1000G_ref_for_king: "/storage/burlo/cocca/resources/1000GP_phase3/king/KGref.bed" 
```

### SNP array data

In order to perform Non Reference Discordance calculation, the user need to provide the pipeline a VCF file, previously formatted (correct genome reference build, correct REF/ALT alignment).
The absolute path to this file has to be provided with the parameter **snp_array_data** in the **path** block of the config file.

This comparison is useful to detect sample contamination and genotyping errors, by comparison with a more trusted dataset. So it is advisable to perform the comparison even if other genetic data is available only for a subset of samples.
In case no other data is available for any sample in the current callset, the parameter in the config file should be set to **"FALSE"**, in order to disable this comparison.


### Other requirements

Manifest file following the template provided in the **resource** folder, space separated and with the header line:

```
SAMPLE_ID COHORT sex SEQ

```

The absolute path of this file has to be specified with the parameter **"manifest_table"** of the config file.